{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca91bd6",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a8dcd",
   "metadata": {},
   "source": [
    "## Read Tweets Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(' since:2021-11-1 until:2021-11-30 lang:en').get_items()):\n",
    "    tweets_list.append([tweet.content, tweet.user.username, tweet.date, tweet.id])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['text', 'user', 'date', 'Tweet Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef094d41",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c655c",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d464a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['user', 'date', 'Tweet Id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488f874",
   "metadata": {},
   "source": [
    "Remove URLs from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+','', text)\n",
    "\n",
    "df['text'] = df['text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8bc35",
   "metadata": {},
   "source": [
    "Lowercase all alphabets and remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['text'].str.lower().str.replace('[^\\w\\s]', ' ').str.replace(' +', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcfbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"text\": 0, \"clean\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace6b49",
   "metadata": {},
   "source": [
    "Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df.apply(lambda row: nltk.word_tokenize(row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a737daa",
   "metadata": {},
   "source": [
    "Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419605f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45785658",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m','n','o','p','q','r','s','t', 'u', 'v', 'w', 'x', 'y', 'z', \"about\", \"across\", \"after\", \"all\", \"also\", \"an\", \"and\", \"another\", \"added\",\n",
    "\"any\", \"are\", \"as\", \"at\", \"basically\", \"be\", \"because\", 'become', \"been\", \"before\", \"being\", \"between\",\"both\", \"but\", \"by\",\"came\",\"can\",\"come\",\"could\",\"did\",\"do\",\"does\",\"each\",\"else\",\"every\",\"either\",\"especially\", \"for\",\"from\",\"get\",\"given\",\"gets\",\n",
    "'give','gives',\"got\",\"goes\",\"had\",\"has\",\"have\",\"he\",\"her\",\"here\",\"him\",\"himself\",\"his\",\"how\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"lands\",\"like\",\"make\",\"making\", \"made\", \"many\",\"may\",\"me\",\"might\",\"more\",\"most\",\"much\",\"must\",\"my\",\"never\",\"provide\", \n",
    "\"provides\", \"perhaps\",\"no\",\"now\",\"of\",\"on\",\"only\",\"or\",\"other\", \"our\",\"out\",\"over\",\"re\",\"said\",\"same\",\"see\",\"should\",\"since\",\"so\",\"some\",\"still\",\"such\",\"seeing\", \"see\", \"take\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\n",
    "\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"up\",\"use\",\"using\",\"used\", \"underway\", \"very\",\"want\",\"was\",\"way\",\"we\",\"well\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"whilst\",\"who\",\"will\",\"with\",\"would\",\"you\",\"your\", \n",
    "'etc', 'via', 'eg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words += ['hi','\\n','\\n\\n', '&amp;', ' ', '.', '-', 'got', \"it's\", 'it’s', \"i'm\", 'i’m', 'im', 'want', 'like', '$', '@', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'rt', 'feel', 'give', 'giving', 'help', 'said', 'also', 'gave', 'like', 'going', 'even']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c055d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df[1].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ca7a5",
   "metadata": {},
   "source": [
    "Perform Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df[1] = df[1].apply(lambda x: [wordnet_lemmatizer.lemmatize(y) for y in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3f3bc",
   "metadata": {},
   "source": [
    "## Create a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5350ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all words in all documents\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "# filter extreme cases out of dictionary\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# create BOW dictionary\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e72cac",
   "metadata": {},
   "source": [
    "## Create LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LDA model using preferred hyperparameters\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                         num_topics=5, \n",
    "                                         id2word=dictionary, \n",
    "                                         passes=4, \n",
    "                                         workers=2,\n",
    "                                         random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca47235",
   "metadata": {},
   "source": [
    "View LDA topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0e701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a76ba",
   "metadata": {},
   "source": [
    "### Calculate LDA Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8601510",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(model=lda_model, corpus=bow_corpus, texts=docs, coherence='c_v')\n",
    "coherence_lda = cm.get_coherence() \n",
    "print(coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18645770",
   "metadata": {},
   "source": [
    "## Create GSDMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable containing length of dictionary/vocab\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "# initialize GSDMM\n",
    "gsdmm = MovieGroupProcess(K=15, alpha=0.1, beta=0.3, n_iters=15)\n",
    "\n",
    "# fit GSDMM model\n",
    "y = gsdmm.fit(docs, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c013830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e95db",
   "metadata": {},
   "source": [
    "Display GSDMM topics with top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of documents per topic\n",
    "doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n",
    "\n",
    "# get top words in topics\n",
    "top_words(gsdmm.cluster_word_distribution, top_index, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a71cef",
   "metadata": {},
   "source": [
    "Create Lists from GSDMM topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_lists(model, top_clusters, n_words):\n",
    "    '''\n",
    "    Gets lists of words in topics as a list of lists.\n",
    "    \n",
    "    model: gsdmm instance\n",
    "    top_clusters:  numpy array containing indices of top_clusters\n",
    "    n_words: top n number of words to include\n",
    "    \n",
    "    '''\n",
    "    # create empty list to contain topics\n",
    "    topics = []\n",
    "    \n",
    "    # iterate over top n clusters\n",
    "    for cluster in top_clusters:\n",
    "        #create sorted dictionary of word distributions\n",
    "        sorted_dict = sorted(model.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:n_words]\n",
    "         \n",
    "        #create empty list to contain words\n",
    "        topic = []\n",
    "        \n",
    "        #iterate over top n words in topic\n",
    "        for k,v in sorted_dict:\n",
    "            #append words to topic list\n",
    "            topic.append(k)\n",
    "            \n",
    "        #append topics to topics list    \n",
    "        topics.append(topic)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# get topics to feed to coherence model\n",
    "topics = get_topics_lists(gsdmm, top_index, 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573b951",
   "metadata": {},
   "source": [
    "### Calculate GSDMM Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model using Topic Coherence score\n",
    "cm_gsdmm = CoherenceModel(topics=topics, dictionary=dictionary, corpus=bow_corpus, texts=docs, coherence='c_v')\n",
    "\n",
    "# get coherence value\n",
    "coherence_gsdmm = cm_gsdmm.get_coherence()  \n",
    "\n",
    "print(coherence_gsdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855454bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_words(gsdmm.cluster_word_distribution, top_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gsdmm = CoherenceModel(topics=topics, dictionary=dictionary, corpus=bow_corpus, texts=docs, coherence='c_v')\n",
    "coherence_gsdmm = cm_gsdmm.get_coherence()  \n",
    "print(coherence_gsdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cfa51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
